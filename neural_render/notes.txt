2021-05-15
Started many jobs as we now have a decent prototype (of the most basic thing).
Seems like wider is better. No multiplier is way worse. 
mse vs perceptual loss probably doesn't matter much, will keep perceptual for now.
Celu for output doesn't seem better, just keep Relu.
More mul size doesn't seem better.
Larger output multiplier doesn't seem better.

2021-05-16
Residual connection is important (no real surprise here...)
Actually, more mul size is better (and maybe 1:1 is the right ratio).
Deeper is slightly better (but maybe not best way to make net bigger).
Results around different output block and wider are questionable because
of different batch size (use same batch size).
Doesn't seem like hidden size expansion accomplishes anything (this is
pretty surprising to me).

For bizarre and unclear reasons:
  - large hidden feed forward with multiply: fine
  - large hidden feed forward with multiply + output extension: fine
  - not large (1x multiplier) hidden feed forward with multiply + output
    extension: doesn't train
  - not large (1x multiplier) hidden feed forward with multiply: bad (but does
    train a bit)

So conclusion is just use 1 multiply per block. Also probably worth looking
into output extension somewhat...

Layer norm isn't very important, but it does seem slightly better and
it reduces noise a bit (maybe?)

2021-05-17
Unsurprisingly, bigger is better.

Seems like lr isn't actually that important, but training time is very important.
I may need to give the net an absurd amount of training time...

Better features for input?
  - compute "cut off region" (for when emitter triangle is partially behind)
  - compute regions of emitter which are totally cut off
  - compute regions of receiver which are totally cut off
  - compute regions of emitter/receiver which are effected.
  - Any "nice" features?

Also, how to handle multiple blocking triangles? Approaches:
  - transformer over blockers (could work might be slow)
  - simple reduction over high dimensional feature of blockers 
    (could work (to some extent...), shouldn't be too slow...)
  - Some sort of set union intersection approach (can't seem to
    find a coherent way of doing this...)
For now, use blocking feature reduction I think.


2021-06-06
Approach: analyze overall scene using some features (probably with
transformer). Then run bounces.

2021-06-09
Feature ideas:
 - triangle features
 - masking possibly shadowing triangles
 - standard triangle to triangle features
 - probably will just learn slower than full features?
 - maybe use some supervision on some sort of a shadow feature involving rays?

So start proposal:
 - full transformer with non-ideal features 

Then try additional ray supervision.
Then try additional features.
Then try network adjustment.

Rotation invariant transformer: paper is specific to points in 3D space, so some porting would be required (no need to do this just yet).
